{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification with Python",
      "provenance": [],
      "collapsed_sections": [
        "kLG2VTrnTvYL",
        "XecOwPNorl2W",
        "J4wfHZwQrs-t",
        "a9BPYqunry97",
        "7KMRBJ7zr9HD",
        "UtwSX1FmVPtw",
        "JKiQBwQuVd9k",
        "iUNbvIvnT7ep",
        "dfbEEtXuWXuo",
        "ueIz-A-eWga9",
        "kHzztFd5Wpx_",
        "z58VpwHoasH_",
        "jA28XDA03Q9-",
        "qI23jTyh5XDU"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciekash/Text-Classification-with-Python-Project/blob/main/Text_Classification_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF3cTlYmPj-Q"
      },
      "source": [
        "# <font color='#2F4F4F'>AfterWork Data Science: Text Classification with Python - Project</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLG2VTrnTvYL"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 1. Business Understading </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XecOwPNorl2W"
      },
      "source": [
        "### a) Specifying the Research Question\n",
        "\n",
        "Build a text classification model that classifies a given text input as written in english or in dutch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wfHZwQrs-t"
      },
      "source": [
        "### b) Defining the Metric for Success\n",
        "\n",
        "Build a classification model with an accuracy of score of atleast 85%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BPYqunry97"
      },
      "source": [
        "### c) Understanding the Context \n",
        "\n",
        "You work as a Computational Linguist for a Global firm, collaborating with Engineers and\n",
        "Researchers in Assistant and Research & Machine Intelligence to develop language\n",
        "understanding models that improve our ability to understand and generate natural\n",
        "language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMRBJ7zr9HD"
      },
      "source": [
        "### d) Recording the Experimental Design\n",
        "\n",
        "* Business Understanding\n",
        "* Data Exploration\n",
        "* Data Preparation\n",
        "* Data Modeling and Evaluation\n",
        "* Summary of Findings \n",
        "* Recommendation\n",
        "* Challenges\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtwSX1FmVPtw"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 2. Data Importation</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdQLGhWqVRTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44698f3a-09b3-41b3-ef34-3f9492014349"
      },
      "source": [
        "# Importing the required libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd # library for data manipulation\n",
        "import numpy as np  # librariy for scientific computations\n",
        "import re           # regex library to perform text preprocessing\n",
        "import string       # library to work with strings\n",
        "import nltk         # library for natural language processing\n",
        "import scipy        # scientific computing \n",
        "import seaborn as sns # library for data visualisation\n",
        "\n",
        "# to display all columns\n",
        "pd.set_option('display.max.columns', None)\n",
        "\n",
        "# to display the entire contents of a cell\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Library for Stop words\n",
        "!pip3 install wordninja\n",
        "!pip3 install textblob\n",
        "import wordninja \n",
        "from textblob import TextBlob\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# Library for Lemmatization\n",
        "nltk.download('wordnet')\n",
        "from textblob import Word\n",
        "\n",
        "# Library for Noun count\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Library for TD-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "\n",
        "# Library for metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordninja in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i6Tr31PeCK0"
      },
      "source": [
        "# Custom Functions\n",
        "# ---\n",
        "#\n",
        "\n",
        "# Avg. words\n",
        "def avg_word(sentence):\n",
        "  words = sentence.split()\n",
        "  try:\n",
        "    z = (sum(len(word) for word in words)/len(words))\n",
        "  except ZeroDivisionError:\n",
        "    z = 0 \n",
        "  return z\n",
        "\n",
        "# Noun count\n",
        "pos_dic = {\n",
        "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
        "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
        "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
        "    'adj' :  ['JJ','JJR','JJS'],\n",
        "    'adv' : ['RB','RBR','RBS','WRB']\n",
        "}\n",
        "\n",
        "def pos_check(x, flag):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_dic[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt\n",
        "\n",
        "# Subjectivity \n",
        "def get_subjectivity(tweet):\n",
        "    try:\n",
        "        textblob = TextBlob(unicode(tweet, 'utf-8'))\n",
        "        subj = textblob.sentiment.subjectivity\n",
        "    except:\n",
        "        subj = 0.0\n",
        "    return subj\n",
        "\n",
        "# Polarity\n",
        "def get_polarity(tweet):\n",
        "    try:\n",
        "        textblob = TextBlob(unicode(tweet, 'utf-8'))\n",
        "        pol = textblob.sentiment.polarity\n",
        "    except:\n",
        "        pol = 0.0\n",
        "    return pol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taugd1WVVYBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc183109-cbcf-47be-acea-b12e05b4c3a2"
      },
      "source": [
        "# loading and previewing the dataset\n",
        "df = pd.read_csv('http://bit.ly/EnglishNDutchDs') \n",
        "df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                 text  \\\n",
              "337   de vernoemd bedrijf Electric. Edison begon, weigerde uitdaging die de van niet concurrent begrijpt wisselstroom   \n",
              "909                     Known for his signature knuckleball Wakefield won his th career game on September against the   \n",
              "840                  De wetenschappelijke naam van dit geslacht is voor het eerst geldig gepubliceerd in door Girault   \n",
              "1027                                       The core of Arzawa is believed to be along the Kaystros River now known as   \n",
              "537                                   wist in zijn eerste drie jaar bij PSV niet door te breken en moest voornamelijk   \n",
              "\n",
              "     label  \n",
              "337     nl  \n",
              "909     en  \n",
              "840     nl  \n",
              "1027    en  \n",
              "537     nl  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c3b9542-2350-42cb-bd44-1026d4e326c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>de vernoemd bedrijf Electric. Edison begon, weigerde uitdaging die de van niet concurrent begrijpt wisselstroom</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>909</th>\n",
              "      <td>Known for his signature knuckleball Wakefield won his th career game on September against the</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>De wetenschappelijke naam van dit geslacht is voor het eerst geldig gepubliceerd in door Girault</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>The core of Arzawa is believed to be along the Kaystros River now known as</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>wist in zijn eerste drie jaar bij PSV niet door te breken en moest voornamelijk</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c3b9542-2350-42cb-bd44-1026d4e326c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c3b9542-2350-42cb-bd44-1026d4e326c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c3b9542-2350-42cb-bd44-1026d4e326c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKiQBwQuVd9k"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 3. Data Exploration</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKMZcfxGVo3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd5e6ac-3685-4c40-b9ad-ad9d3f1867c1"
      },
      "source": [
        "# check dataset shape\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1069, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8s9wj4_Vo3r"
      },
      "source": [
        "Our dataset has 1069 records and 2 variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov8nTc9cVo3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42549205-7571-4e39-ec46-b7031eae4473"
      },
      "source": [
        "# preview variable datatypes\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     object\n",
              "label    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COOwPNRPVo3w"
      },
      "source": [
        "Both variables have the data type object. This is fine for the text variable, however for the label, we will need to convert it to a numerical format. We will do this later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE7Ik7ox85g6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "3939dac8-6b33-4d4f-8012-dcdb0463d878"
      },
      "source": [
        "# plotting the distribution of label\n",
        "# ---\n",
        "#\n",
        "sns.countplot(df['label']);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv9z0csQX5C9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2726271-d5bb-4ecb-c6d5-a93bf44375d8"
      },
      "source": [
        "# investigating the label distribution\n",
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nl    535\n",
              "en    534\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABx4lS8HZDxp"
      },
      "source": [
        "From above, we can see that our dataset is unbalanced thus we will need to sample equal no. of records for each label during data preparation to make a balanced dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUNbvIvnT7ep"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 4. Data Preparation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfbEEtXuWXuo"
      },
      "source": [
        "### <font color='#2F4F4F'>3.1 Data Cleaning</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLde07_NVo3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c91b3db3-af02-4cc3-9a4d-636c4f3fcd45"
      },
      "source": [
        "# check for duplicates\n",
        "df.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY9eV5l6V_Xv"
      },
      "source": [
        "There are 10 duplicates. We will need to drop these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQLb6TqVVo3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893395cc-b111-4a1f-a5c6-ff1b6b825afd"
      },
      "source": [
        "# check for missing values\n",
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npaYUA7bVo33"
      },
      "source": [
        "No missing values found. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZGm8pnHWGrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e7d883-c144-4a1b-c25c-3971f8489c61"
      },
      "source": [
        "# dropping our duplicates\n",
        "df = df.drop_duplicates()\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1059, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0IQmdGugKGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cdff85-6ba0-45e2-c3f5-18ad1c0529d1"
      },
      "source": [
        "# What values are in our label variable?\n",
        "# ---\n",
        "#\n",
        "df.label.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['en', 'nl'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzZsUs0FZDRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e256a1-62c7-4441-90e6-0b5fe8e3dc2a"
      },
      "source": [
        "# sampling text with en \n",
        "df_en = df[df[\"label\"] == 'en'] \n",
        "df_en = df_en.sample(200)\n",
        "\n",
        "# sampling text with nl \n",
        "df_nl = df[df[\"label\"] == 'nl'] \n",
        "df_nl = df_nl.sample(200)\n",
        "\n",
        "# combining our dataframes\n",
        "df = pd.concat([df_en, df_nl])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                       text  \\\n",
              "190                          studio motion film home modified movie eastman film u intended   \n",
              "56                                succeed candidate step big leader34 local opposition five   \n",
              "871                                            building defunct used centre outdoor pursuit   \n",
              "962     evolving capacity concept education child development youth development program led   \n",
              "507  decision tree due added sparsity permit nongreedy learning method monotonic constraint   \n",
              "\n",
              "    label  length_of_text  word_count  avg_word_length  noun_count  \\\n",
              "190    en              62          10         5.300000           8   \n",
              "56     en              57           8         6.250000           3   \n",
              "871    en              44           6         6.500000           3   \n",
              "962    en              83          10         7.400000           8   \n",
              "507    en              86          11         6.909091           6   \n",
              "\n",
              "     verb_count  adj_count  adv_count  pron_count  subjectivity  polarity  \n",
              "190           2          0          0           0           0.0       0.0  \n",
              "56            1          3          0           0           0.0       0.0  \n",
              "871           1          2          0           0           0.0       0.0  \n",
              "962           2          0          0           0           0.0       0.0  \n",
              "507           2          2          0           0           0.0       0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30434559-c3eb-4d49-a610-53f78d2a1b58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>length_of_text</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>noun_count</th>\n",
              "      <th>verb_count</th>\n",
              "      <th>adj_count</th>\n",
              "      <th>adv_count</th>\n",
              "      <th>pron_count</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>studio motion film home modified movie eastman film u intended</td>\n",
              "      <td>en</td>\n",
              "      <td>62</td>\n",
              "      <td>10</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>succeed candidate step big leader34 local opposition five</td>\n",
              "      <td>en</td>\n",
              "      <td>57</td>\n",
              "      <td>8</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>building defunct used centre outdoor pursuit</td>\n",
              "      <td>en</td>\n",
              "      <td>44</td>\n",
              "      <td>6</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>evolving capacity concept education child development youth development program led</td>\n",
              "      <td>en</td>\n",
              "      <td>83</td>\n",
              "      <td>10</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>decision tree due added sparsity permit nongreedy learning method monotonic constraint</td>\n",
              "      <td>en</td>\n",
              "      <td>86</td>\n",
              "      <td>11</td>\n",
              "      <td>6.909091</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30434559-c3eb-4d49-a610-53f78d2a1b58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30434559-c3eb-4d49-a610-53f78d2a1b58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30434559-c3eb-4d49-a610-53f78d2a1b58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu0mUgQgfNxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3badc0bc-9395-4655-a5ed-d595985ebccd"
      },
      "source": [
        "# investigating the label distribution\n",
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "en    200\n",
              "nl    200\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABEvQqbfXHF"
      },
      "source": [
        "We now have our balanced dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueIz-A-eWga9"
      },
      "source": [
        "### <font color='#2F4F4F'> 3.2 Text Cleaning</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATi3KYKuWtJ5"
      },
      "source": [
        "# We will create a custom function that will contain all the text cleaning \n",
        "# techniques. We can then reuse the same function for cleaning new data\n",
        "# without rewriting the code.\n",
        "# ---\n",
        "# \n",
        "def text_cleaning(text):\n",
        "  # Removing url/links\n",
        "  df['text'] = df.text.apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+','', str(x)))\n",
        "\n",
        "  # Removing @ and # characters and replacing them with space\n",
        "  df['text'] = df.text.str.replace('#',' ')\n",
        "  df['text'] = df.text.str.replace('@',' ') \n",
        "\n",
        "  # Conversion to lowercase \n",
        "  df['text'] = df.text.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "  # Removing punctuation characters\n",
        "  df['text'] = df.text.str.replace('[^\\w\\s]','')\n",
        "\n",
        "  # Removing stop words\n",
        "  df['text'] = df.text.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "\n",
        "  # Lemmatization\n",
        "  df['text'] = df.text.apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXhae-QrhX85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "c9f322c1-19c5-41cf-c57e-3f8daa92fae1"
      },
      "source": [
        "# Applying the text_cleaning function to our dataframe.\n",
        "# ---\n",
        "# NB: This process may take 5-10 min.\n",
        "# ---\n",
        "#\n",
        "df['text'].apply(text_cleaning)\n",
        "df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                      text  \\\n",
              "181                                                  since preserved introduced early wheatstone published   \n",
              "964                  concept evolving capacity employed internationally direct alternative popular concept   \n",
              "659  augustus 2018 geopend al het voorlopig zuidelijke eindpunt van de solntsevskajaradiushet de bedoeling   \n",
              "23                  wide fourthranked 1994 african playing african black vast african claim struggle never   \n",
              "931                                        susukino often noted 薄野 kanji ススキノ katakana directly translated   \n",
              "\n",
              "    label  \n",
              "181    en  \n",
              "964    en  \n",
              "659    nl  \n",
              "23     en  \n",
              "931    en  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64583ad7-4aca-425b-ab74-1f527402b0d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>since preserved introduced early wheatstone published</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>concept evolving capacity employed internationally direct alternative popular concept</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659</th>\n",
              "      <td>augustus 2018 geopend al het voorlopig zuidelijke eindpunt van de solntsevskajaradiushet de bedoeling</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>wide fourthranked 1994 african playing african black vast african claim struggle never</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>susukino often noted 薄野 kanji ススキノ katakana directly translated</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64583ad7-4aca-425b-ab74-1f527402b0d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64583ad7-4aca-425b-ab74-1f527402b0d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64583ad7-4aca-425b-ab74-1f527402b0d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHzztFd5Wpx_"
      },
      "source": [
        "### <font color='#2F4F4F'> 3.3 Feature Engineering</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91ZkaNK4Wth2"
      },
      "source": [
        "# We will create a custom function that will contain all the \n",
        "# feature engineering techniques. We can then use this function \n",
        "# for cleaning new data. \n",
        "\n",
        "\n",
        "def feature_engineering(text):\n",
        "  # Length of tweet\n",
        "  df['length_of_text'] = df.text.str.len()\n",
        "\n",
        "  # Word count \n",
        "  df['word_count'] = df.text.apply(lambda x: len(str(x).split(\" \")))\n",
        "\n",
        "  # Word density (Average no. of words / tweet)\n",
        "  df['avg_word_length'] = df.text.apply(lambda x: avg_word(x)) \n",
        "  \n",
        "  # Noun Count\n",
        "  df['noun_count'] = df.text.apply(lambda x: pos_check(x, 'noun'))\n",
        "\n",
        "  # Verb Count\n",
        "  df['verb_count'] = df.text.apply(lambda x: pos_check(x, 'verb'))\n",
        "\n",
        "  # Adjective Count / Tweet\n",
        "  df['adj_count'] = df.text.apply(lambda x: pos_check(x, 'adj'))\n",
        "\n",
        "  # Adverb Count / Tweet\n",
        "  df['adv_count'] = df.text.apply(lambda x: pos_check(x, 'adv'))\n",
        "\n",
        "  # Pronoun \n",
        "  df['pron_count'] = df.text.apply(lambda x: pos_check(x, 'pron'))\n",
        "\n",
        "  # Subjectivity \n",
        "  df['subjectivity'] = df.text.apply(get_subjectivity)\n",
        "\n",
        "  # Polarity\n",
        "  df['polarity'] = df.text.apply(get_polarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dli-H5lNjESt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9eeda9-0487-46a8-c34e-4969bba52644"
      },
      "source": [
        "# Applying the custom feature engineering function to our dataframe.\n",
        "# This process may take 2-5 min.\n",
        "# ---\n",
        "#\n",
        "df['text'].apply(feature_engineering)\n",
        "df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                              text  \\\n",
              "332                                   van zij john daarna zijn totdat peter het hertrouwde sloane huwelijk haar de   \n",
              "694                                     spel kwam noordamerika uit op 28 september 2010 japan op 30 september 2010   \n",
              "339   zich westinghouse betalen zijn en om de patenten echter grondleggers nadien kon en tesla gelijkstroomsysteem   \n",
              "1016                                                        became member serbian learned society society preceded   \n",
              "955                                                             cougar also come picked win wcc woman soccer crown   \n",
              "\n",
              "     label  length_of_text  word_count  avg_word_length  noun_count  \\\n",
              "332     nl              76          13         4.923077          12   \n",
              "694     nl              74          13         4.769231           6   \n",
              "339     nl             108          15         6.266667           6   \n",
              "1016    en              54           7         6.857143           4   \n",
              "955     en              50           9         4.666667           2   \n",
              "\n",
              "      verb_count  adj_count  adv_count  pron_count  subjectivity  polarity  \n",
              "332            0          0          0           0           0.0       0.0  \n",
              "694            2          0          0           0           0.0       0.0  \n",
              "339            2          1          0           0           0.0       0.0  \n",
              "1016           3          0          0           0           0.0       0.0  \n",
              "955            3          3          1           0           0.0       0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbf2c790-dc85-4f77-88d3-843f2597ed96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>length_of_text</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>noun_count</th>\n",
              "      <th>verb_count</th>\n",
              "      <th>adj_count</th>\n",
              "      <th>adv_count</th>\n",
              "      <th>pron_count</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>van zij john daarna zijn totdat peter het hertrouwde sloane huwelijk haar de</td>\n",
              "      <td>nl</td>\n",
              "      <td>76</td>\n",
              "      <td>13</td>\n",
              "      <td>4.923077</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>spel kwam noordamerika uit op 28 september 2010 japan op 30 september 2010</td>\n",
              "      <td>nl</td>\n",
              "      <td>74</td>\n",
              "      <td>13</td>\n",
              "      <td>4.769231</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>zich westinghouse betalen zijn en om de patenten echter grondleggers nadien kon en tesla gelijkstroomsysteem</td>\n",
              "      <td>nl</td>\n",
              "      <td>108</td>\n",
              "      <td>15</td>\n",
              "      <td>6.266667</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>became member serbian learned society society preceded</td>\n",
              "      <td>en</td>\n",
              "      <td>54</td>\n",
              "      <td>7</td>\n",
              "      <td>6.857143</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>cougar also come picked win wcc woman soccer crown</td>\n",
              "      <td>en</td>\n",
              "      <td>50</td>\n",
              "      <td>9</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbf2c790-dc85-4f77-88d3-843f2597ed96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbf2c790-dc85-4f77-88d3-843f2597ed96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbf2c790-dc85-4f77-88d3-843f2597ed96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPUG6EiQjN3B"
      },
      "source": [
        "# Performing further feature engineering techniques\n",
        "# ---\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer()\n",
        "\n",
        "# Importing the TfidfVectorizer \n",
        "# ---\n",
        "#\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Feature Construction: Word Level N-Gram TF-IDF Feature \n",
        "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', ngram_range=(1,3),  stop_words= 'english')\n",
        "df_word_vect = tfidf.fit_transform(df.text) \n",
        "\n",
        "# Feature Construction: Character Level N-Gram TF-IDF \n",
        "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='char', ngram_range=(1,3),  stop_words= 'english')\n",
        "df_char_vect = tfidf.fit_transform(df.text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU5dGj1_jO8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02686a2-9624-4fa8-e78a-f88f63ad36ea"
      },
      "source": [
        "# Let's prepare the constructed features for modeling\n",
        "# ---\n",
        "# We will select all variables but the target (which is the label) and text variables \n",
        "# ---\n",
        "#  \n",
        "X_metadata = np.array(df[df.columns.difference(['label', 'text'])])#converting to array as well\n",
        "X_metadata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.        ,  0.        ,  7.66666667, ...,  0.        ,\n",
              "         2.        , 12.        ],\n",
              "       [ 3.        ,  1.        ,  6.8       , ...,  0.        ,\n",
              "         2.        , 10.        ],\n",
              "       [ 2.        ,  0.        ,  7.        , ...,  0.        ,\n",
              "         2.        ,  9.        ],\n",
              "       ...,\n",
              "       [ 1.        ,  0.        ,  5.6       , ...,  0.        ,\n",
              "         2.        , 15.        ],\n",
              "       [ 1.        ,  0.        ,  5.73333333, ...,  0.        ,\n",
              "         1.        , 15.        ],\n",
              "       [ 1.        ,  0.        ,  5.        , ...,  0.        ,\n",
              "         1.        , 14.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8F3QQ6PjZsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc290cee-187d-458e-a1bf-688c9671ecd4"
      },
      "source": [
        "# We combine our two tfidf (sparse) matrices and X_metadata\n",
        "# ---\n",
        "#\n",
        "X = scipy.sparse.hstack([df_word_vect, df_char_vect, X_metadata])\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<400x2010 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 52176 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-YdQkYqoYjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b8e7669-3eb8-4715-8de1-c5b0716a6d22"
      },
      "source": [
        "# Label Preparation i.e. replacing categorial values with numerical ones\n",
        "# ---  \n",
        "#\n",
        "y = np.array(df['label'].replace(['en', 'nl'], ['0','1']))\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z58VpwHoasH_"
      },
      "source": [
        "##  <font color='#2F4F4F'>Step 5. Data Modeling</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKm33MJYasH_"
      },
      "source": [
        "We will carry out 10 types of classification analysis, namely:\n",
        "1.  Logistic Regression\n",
        "3.  Decision Trees Classification\n",
        "4.  Support Vector Machine (SVM) Classification\n",
        "5. K-Nearest Neighbors (KNN) Classification\n",
        "6.  Gaussian Naive Bayes (NB) Classification\n",
        "7.  BaggingClassifier\n",
        "8.  RandomForestClassifier\n",
        "9.  AdaBoostClassifier\n",
        "10. GradientBoostingClassifier\n",
        "\n",
        "We use their default parameters then compare the different classification models to assess the best performing one(s). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kByQ2gGOasIN"
      },
      "source": [
        "# splitting into 80-20 train-test sets\n",
        "# ---\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3hBaXKTasIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14531d3b-12d2-4aaa-eb80-0cfbe5062c9b"
      },
      "source": [
        "# Importing the algorithms\n",
        "# ---\n",
        "# \n",
        "from sklearn.linear_model import LogisticRegression      # Logistic Regression Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier          # Decision Tree Classifier\n",
        "from sklearn.svm import SVC                              # SVM Classifier\n",
        "from sklearn.naive_bayes import MultinomialNB            # Naive Bayes Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier       # KNN Classifier\n",
        "\n",
        "# Ensemble classifiers\n",
        "from sklearn.ensemble import BaggingClassifier           # Bagging Meta-Estimator Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier      # RandomForest Classifier \n",
        "from sklearn.ensemble import AdaBoostClassifier          # AdaBoost Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier  # AdaBoost GradientBoostingClassifier\n",
        "import xgboost as xgb                                    # Importing the XGBoost library\n",
        "\n",
        "\n",
        "# Instantiating our models\n",
        "\n",
        "\n",
        "logistic_classifier = LogisticRegression(solver='saga', max_iter=800, multi_class='multinomial') # solver works well with a large dataset like ours\n",
        "decision_classifier = DecisionTreeClassifier(random_state=42)\n",
        "svm_classifier = SVC()\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "naive_classifier = MultinomialNB() \n",
        "\n",
        "bagging_meta_classifier = BaggingClassifier()\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "ada_boost_classifier = AdaBoostClassifier(random_state=42)\n",
        "gbm_classifier = GradientBoostingClassifier(random_state=42) \n",
        "xg_boost_classifier = xgb.XGBClassifier() \n",
        "\n",
        "# fitting our classifiers to the training data\n",
        "# ---\n",
        "logistic_classifier.fit(X_train, y_train)\n",
        "decision_classifier.fit(X_train, y_train)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "naive_classifier.fit(X_train, y_train) \n",
        "\n",
        "bagging_meta_classifier.fit(X_train, y_train)\n",
        "random_forest_classifier.fit(X_train, y_train)\n",
        "ada_boost_classifier.fit(X_train, y_train)\n",
        "gbm_classifier.fit(X_train, y_train)\n",
        "xg_boost_classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# making predictions\n",
        "\n",
        "logistic_y_prediction = logistic_classifier.predict(X_test) \n",
        "decision_y_prediction = decision_classifier.predict(X_test) \n",
        "svm_y_prediction = svm_classifier.predict(X_test) \n",
        "knn_y_prediction = knn_classifier.predict(X_test) \n",
        "naive_y_prediction = naive_classifier.predict(X_test)  \n",
        "\n",
        "bagging_y_classifier = bagging_meta_classifier.predict(X_test) \n",
        "random_forest_y_classifier = random_forest_classifier.predict(X_test) \n",
        "ada_boost_y_classifier = ada_boost_classifier.predict(X_test)\n",
        "gbm_y_classifier = gbm_classifier.predict(X_test)\n",
        "xg_boost_y_classifier = xg_boost_classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfXCA87-asIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456d8f84-6c68-417c-f5d6-3a1078dcd470"
      },
      "source": [
        "# Evaluating the Models\n",
        "# ---\n",
        "\n",
        "print(\"Logistic Regression Classifier\", accuracy_score(logistic_y_prediction, y_test))\n",
        "print(\"Decision Trees Classifier\", accuracy_score(decision_y_prediction, y_test))\n",
        "print(\"SVN Classifier\", accuracy_score(svm_y_prediction, y_test))\n",
        "print(\"KNN Classifier\", accuracy_score(knn_y_prediction, y_test))\n",
        "print(\"Naive Bayes Classifier\", accuracy_score(naive_y_prediction, y_test))\n",
        " \n",
        "print(\"Bagging Classifier\", accuracy_score(bagging_y_classifier, y_test))\n",
        "print(\"Random Forest Classifier\", accuracy_score(random_forest_y_classifier, y_test))\n",
        "print(\"Ada Boost Classifier\", accuracy_score(ada_boost_y_classifier, y_test))\n",
        "print(\"GBM Classifier\", accuracy_score(gbm_y_classifier, y_test))\n",
        "print(\"XGBoost Classifier\", accuracy_score(xg_boost_y_classifier, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier 0.975\n",
            "Decision Trees Classifier 0.95\n",
            "SVN Classifier 0.875\n",
            "KNN Classifier 0.9125\n",
            "Naive Bayes Classifier 0.9625\n",
            "Bagging Classifier 1.0\n",
            "Random Forest Classifier 1.0\n",
            "Ada Boost Classifier 1.0\n",
            "GBM Classifier 1.0\n",
            "XGBoost Classifier 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ0H_nXpo-lK"
      },
      "source": [
        "Your observation about the performance of the models..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyF5hh38pu5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62aaf07d-e008-42de-d8cb-1e89b1154da9"
      },
      "source": [
        "# Confusion matrices\n",
        "# ---\n",
        "# \n",
        "print('Logistic Regression Classifier:')\n",
        "print(confusion_matrix(logistic_y_prediction, y_test))\n",
        "\n",
        "print('Decision Trees Classifier:')\n",
        "print(confusion_matrix(decision_y_prediction, y_test))\n",
        "\n",
        "print('SVN Classifier:')\n",
        "print(confusion_matrix(svm_y_prediction, y_test))\n",
        "\n",
        "print('KNN Classifier:')\n",
        "print(confusion_matrix(knn_y_prediction, y_test))\n",
        "\n",
        "print('Naive Bayes Classifier:')\n",
        "print(confusion_matrix(naive_y_prediction, y_test))\n",
        " \n",
        "print('Bagging Classifier:')\n",
        "print(confusion_matrix(bagging_y_classifier, y_test))\n",
        "\n",
        "print('Random Forest Classifier:')\n",
        "print(confusion_matrix(random_forest_y_classifier, y_test))\n",
        "\n",
        "print('Ada Boost Classifier:')\n",
        "print(confusion_matrix(ada_boost_y_classifier, y_test))\n",
        "\n",
        "print('GBM Classifier:')\n",
        "print(confusion_matrix(gbm_y_classifier, y_test))\n",
        "\n",
        "print('XGBoost Classifier:')\n",
        "print(confusion_matrix(xg_boost_y_classifier, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier:\n",
            "[[43  1]\n",
            " [ 1 35]]\n",
            "Decision Trees Classifier:\n",
            "[[42  2]\n",
            " [ 2 34]]\n",
            "SVN Classifier:\n",
            "[[35  1]\n",
            " [ 9 35]]\n",
            "KNN Classifier:\n",
            "[[41  4]\n",
            " [ 3 32]]\n",
            "Naive Bayes Classifier:\n",
            "[[41  0]\n",
            " [ 3 36]]\n",
            "Bagging Classifier:\n",
            "[[43  0]\n",
            " [ 1 36]]\n",
            "Random Forest Classifier:\n",
            "[[44  0]\n",
            " [ 0 36]]\n",
            "Ada Boost Classifier:\n",
            "[[44  0]\n",
            " [ 0 36]]\n",
            "GBM Classifier:\n",
            "[[44  0]\n",
            " [ 0 36]]\n",
            "XGBoost Classifier:\n",
            "[[44  0]\n",
            " [ 0 36]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBJJqpvjp_Nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71ef2c7-457f-451c-eb9c-6c74342a5dfc"
      },
      "source": [
        "# Classification Reports\n",
        "# ---\n",
        "# \n",
        "print(\"Logistic Regression Classifier\", classification_report(logistic_y_prediction, y_test))\n",
        "print(\"Decision Trees Classifier\", classification_report(decision_y_prediction, y_test))\n",
        "print(\"SVM Classifier\", classification_report(svm_y_prediction, y_test))\n",
        "print(\"KNN Classifier\", classification_report(knn_y_prediction, y_test))\n",
        "print(\"Naive Bayes Classifier\", classification_report(naive_y_prediction, y_test))\n",
        " \n",
        "print(\"Bagging Classifier\", classification_report(bagging_y_classifier, y_test))\n",
        "print(\"Random Forest Classifier\", classification_report(random_forest_y_classifier, y_test))\n",
        "print(\"Ada Boost Classifier\", classification_report(ada_boost_y_classifier, y_test))\n",
        "print(\"GBM Classifier\", classification_report(gbm_y_classifier, y_test))\n",
        "print(\"XGBoost Classifier\", classification_report(xg_boost_y_classifier, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        44\n",
            "           1       0.97      0.97      0.97        36\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.97      0.97      0.97        80\n",
            "weighted avg       0.97      0.97      0.97        80\n",
            "\n",
            "Decision Trees Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        44\n",
            "           1       0.94      0.94      0.94        36\n",
            "\n",
            "    accuracy                           0.95        80\n",
            "   macro avg       0.95      0.95      0.95        80\n",
            "weighted avg       0.95      0.95      0.95        80\n",
            "\n",
            "SVM Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.97      0.88        36\n",
            "           1       0.97      0.80      0.88        44\n",
            "\n",
            "    accuracy                           0.88        80\n",
            "   macro avg       0.88      0.88      0.88        80\n",
            "weighted avg       0.89      0.88      0.88        80\n",
            "\n",
            "KNN Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92        45\n",
            "           1       0.89      0.91      0.90        35\n",
            "\n",
            "    accuracy                           0.91        80\n",
            "   macro avg       0.91      0.91      0.91        80\n",
            "weighted avg       0.91      0.91      0.91        80\n",
            "\n",
            "Naive Bayes Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        41\n",
            "           1       1.00      0.92      0.96        39\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.97      0.96      0.96        80\n",
            "weighted avg       0.97      0.96      0.96        80\n",
            "\n",
            "Bagging Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        44\n",
            "           1       1.00      1.00      1.00        36\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n",
            "Random Forest Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        44\n",
            "           1       1.00      1.00      1.00        36\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n",
            "Ada Boost Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        44\n",
            "           1       1.00      1.00      1.00        36\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n",
            "GBM Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        44\n",
            "           1       1.00      1.00      1.00        36\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n",
            "XGBoost Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        44\n",
            "           1       1.00      1.00      1.00        36\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA28XDA03Q9-"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 6. Summary of Findings and Recommendation</font>\n",
        "\n",
        "The bagging and boost model performed best. To improve our model, we can try perfoming other text processing techniques that would better prepare our data for fitting our model. We can also use different vectorizing techniques, implement other machine learning models, perform hyperparameter tuning and sample a balanced dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI23jTyh5XDU"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 7. Challenging our Solution</font>\n",
        "\n",
        "#### a) Did we have the right question?\n",
        "yes\n",
        "\n",
        "#### b) Did we have the right data?\n",
        "yes\n",
        "\n",
        "#### c) What can be done to improve the solution?\n",
        "Our model having an accuracy score of 1 does not need any furthe improvements"
      ]
    }
  ]
}